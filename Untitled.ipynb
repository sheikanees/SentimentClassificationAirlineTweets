{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sentiment Analysis of tweets about Airlines in US using Glove for text embeddings and LSTM network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Author: Sheik Mohamed Anees S/O S A F\n",
    "\n",
    "This machine learning algorithm aims to predict the sentiment for tweets about the various US airlines thereby allowing the management of these airlines to make better informed decisions and thereby improving the reputation of the airline industry in US.\n",
    "\n",
    "After obtaining the tweets with the use of API, this model could perform the classification of the tweets into 3 categories: Positive, Neutral and Negative.  \n",
    "\n",
    "This dataset was obtained from https://www.kaggle.com/crowdflower/twitter-airline-sentiment\n",
    "\n",
    "### Importing all necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "from tensorflow.keras.layers import Dense, Input, GlobalMaxPooling1D, LSTM\n",
    "from tensorflow.keras.layers import Conv1D, MaxPooling1D, Embedding, Dropout\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.initializers import Constant"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Taking a look at the tweets dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       airline_sentiment            text\n",
      "count              14640           14640\n",
      "unique                 3           14427\n",
      "top             negative  @united thanks\n",
      "freq                9178               6\n",
      "  airline_sentiment                                               text\n",
      "0           neutral                @VirginAmerica What @dhepburn said.\n",
      "1          positive  @VirginAmerica plus you've added commercials t...\n",
      "2           neutral  @VirginAmerica I didn't today... Must mean I n...\n",
      "3          negative  @VirginAmerica it's really aggressive to blast...\n",
      "4          negative  @VirginAmerica and it's a really big bad thing...\n"
     ]
    }
   ],
   "source": [
    "airline_sentiments = pd.read_csv('Tweets.csv')\n",
    "airline_sentiments = airline_sentiments.loc[:,[\"airline_sentiment\", \"text\"]]\n",
    "airline_sentiments = airline_sentiments.dropna()\n",
    "print(airline_sentiments.describe())\n",
    "print(airline_sentiments.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adding a new column to the dataset that denotes the airline sentiments in terms of numbers instead whereby 0 = positive, 1 = neutral and 2 = negative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>airline_sentiment</th>\n",
       "      <th>text</th>\n",
       "      <th>sentiment_value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>neutral</td>\n",
       "      <td>@VirginAmerica What @dhepburn said.</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>positive</td>\n",
       "      <td>@VirginAmerica plus you've added commercials t...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>neutral</td>\n",
       "      <td>@VirginAmerica I didn't today... Must mean I n...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>negative</td>\n",
       "      <td>@VirginAmerica it's really aggressive to blast...</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>negative</td>\n",
       "      <td>@VirginAmerica and it's a really big bad thing...</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>negative</td>\n",
       "      <td>@VirginAmerica seriously would pay $30 a fligh...</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>positive</td>\n",
       "      <td>@VirginAmerica yes, nearly every time I fly VX...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>neutral</td>\n",
       "      <td>@VirginAmerica Really missed a prime opportuni...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>positive</td>\n",
       "      <td>@virginamerica Well, I didn't‚Ä¶but NOW I DO! :-D</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>positive</td>\n",
       "      <td>@VirginAmerica it was amazing, and arrived an ...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>neutral</td>\n",
       "      <td>@VirginAmerica did you know that suicide is th...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>positive</td>\n",
       "      <td>@VirginAmerica I &amp;lt;3 pretty graphics. so muc...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>positive</td>\n",
       "      <td>@VirginAmerica This is such a great deal! Alre...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>positive</td>\n",
       "      <td>@VirginAmerica @virginmedia I'm flying your #f...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>positive</td>\n",
       "      <td>@VirginAmerica Thanks!</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>negative</td>\n",
       "      <td>@VirginAmerica SFO-PDX schedule is still MIA.</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>positive</td>\n",
       "      <td>@VirginAmerica So excited for my first cross c...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>negative</td>\n",
       "      <td>@VirginAmerica  I flew from NYC to SFO last we...</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>positive</td>\n",
       "      <td>I ‚ù§Ô∏è flying @VirginAmerica. ‚ò∫Ô∏èüëç</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>positive</td>\n",
       "      <td>@VirginAmerica you know what would be amazingl...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>negative</td>\n",
       "      <td>@VirginAmerica why are your first fares in May...</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>positive</td>\n",
       "      <td>@VirginAmerica I love this graphic. http://t.c...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>positive</td>\n",
       "      <td>@VirginAmerica I love the hipster innovation. ...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>neutral</td>\n",
       "      <td>@VirginAmerica will you be making BOS&amp;gt;LAS n...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>negative</td>\n",
       "      <td>@VirginAmerica you guys messed up my seating.....</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>negative</td>\n",
       "      <td>@VirginAmerica status match program.  I applie...</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>negative</td>\n",
       "      <td>@VirginAmerica What happened 2 ur vegan food o...</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>neutral</td>\n",
       "      <td>@VirginAmerica do you miss me? Don't worry we'...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>negative</td>\n",
       "      <td>@VirginAmerica amazing to me that we can't get...</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>neutral</td>\n",
       "      <td>@VirginAmerica LAX to EWR - Middle seat on a r...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14610</th>\n",
       "      <td>negative</td>\n",
       "      <td>@AmericanAir I understand the weather issue bu...</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14611</th>\n",
       "      <td>neutral</td>\n",
       "      <td>@AmericanAir guarantee no retribution? If so, ...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14612</th>\n",
       "      <td>negative</td>\n",
       "      <td>@AmericanAir a friend is having flight Cancell...</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14613</th>\n",
       "      <td>negative</td>\n",
       "      <td>@AmericanAir I used the \"call back\" feature wi...</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14614</th>\n",
       "      <td>negative</td>\n",
       "      <td>@AmericanAir I need to be at work tomorrow at ...</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14615</th>\n",
       "      <td>negative</td>\n",
       "      <td>@AmericanAir  ugh Dump us in dfw w/no luggage ...</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14616</th>\n",
       "      <td>negative</td>\n",
       "      <td>@AmericanAir Cancelled Flights my flight, does...</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14617</th>\n",
       "      <td>positive</td>\n",
       "      <td>@AmericanAir DMing you now! Big thanks.</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14618</th>\n",
       "      <td>negative</td>\n",
       "      <td>@AmericanAir 3078 is overweight so you pull 2 ...</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14619</th>\n",
       "      <td>positive</td>\n",
       "      <td>@AmericanAir I love your company and your staf...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14620</th>\n",
       "      <td>negative</td>\n",
       "      <td>@AmericanAir I wait 2+ hrs for CS to call me b...</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14621</th>\n",
       "      <td>negative</td>\n",
       "      <td>@AmericanAir I've been on hold for 55 mins abo...</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14622</th>\n",
       "      <td>negative</td>\n",
       "      <td>I just need a place to sleep when I land witho...</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14623</th>\n",
       "      <td>positive</td>\n",
       "      <td>@AmericanAir Love the new planes for the JFK-L...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14624</th>\n",
       "      <td>negative</td>\n",
       "      <td>@AmericanAir Call me Chairman, or call me Emer...</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14625</th>\n",
       "      <td>positive</td>\n",
       "      <td>@AmericanAir Flight 236 was great. Fantastic c...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14626</th>\n",
       "      <td>negative</td>\n",
       "      <td>@AmericanAir Flight 953 NYC-Buenos Aires has b...</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14627</th>\n",
       "      <td>negative</td>\n",
       "      <td>@AmericanAir Flight Cancelled Flightled, can't...</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14628</th>\n",
       "      <td>positive</td>\n",
       "      <td>Thank you. ‚Äú@AmericanAir: @jlhalldc Customer R...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14629</th>\n",
       "      <td>negative</td>\n",
       "      <td>@AmericanAir How do I change my flight if the ...</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14630</th>\n",
       "      <td>positive</td>\n",
       "      <td>@AmericanAir Thanks! He is.</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14631</th>\n",
       "      <td>negative</td>\n",
       "      <td>@AmericanAir thx for nothing on getting us out...</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14632</th>\n",
       "      <td>neutral</td>\n",
       "      <td>‚Äú@AmericanAir: @TilleyMonsta George, that does...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14633</th>\n",
       "      <td>negative</td>\n",
       "      <td>@AmericanAir my flight was Cancelled Flightled...</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14634</th>\n",
       "      <td>negative</td>\n",
       "      <td>@AmericanAir right on cue with the delaysüëå</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14635</th>\n",
       "      <td>positive</td>\n",
       "      <td>@AmericanAir thank you we got on a different f...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14636</th>\n",
       "      <td>negative</td>\n",
       "      <td>@AmericanAir leaving over 20 minutes Late Flig...</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14637</th>\n",
       "      <td>neutral</td>\n",
       "      <td>@AmericanAir Please bring American Airlines to...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14638</th>\n",
       "      <td>negative</td>\n",
       "      <td>@AmericanAir you have my money, you change my ...</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14639</th>\n",
       "      <td>neutral</td>\n",
       "      <td>@AmericanAir we have 8 ppl so we need 2 know h...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>14640 rows √ó 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      airline_sentiment                                               text  \\\n",
       "0               neutral                @VirginAmerica What @dhepburn said.   \n",
       "1              positive  @VirginAmerica plus you've added commercials t...   \n",
       "2               neutral  @VirginAmerica I didn't today... Must mean I n...   \n",
       "3              negative  @VirginAmerica it's really aggressive to blast...   \n",
       "4              negative  @VirginAmerica and it's a really big bad thing...   \n",
       "5              negative  @VirginAmerica seriously would pay $30 a fligh...   \n",
       "6              positive  @VirginAmerica yes, nearly every time I fly VX...   \n",
       "7               neutral  @VirginAmerica Really missed a prime opportuni...   \n",
       "8              positive    @virginamerica Well, I didn't‚Ä¶but NOW I DO! :-D   \n",
       "9              positive  @VirginAmerica it was amazing, and arrived an ...   \n",
       "10              neutral  @VirginAmerica did you know that suicide is th...   \n",
       "11             positive  @VirginAmerica I &lt;3 pretty graphics. so muc...   \n",
       "12             positive  @VirginAmerica This is such a great deal! Alre...   \n",
       "13             positive  @VirginAmerica @virginmedia I'm flying your #f...   \n",
       "14             positive                             @VirginAmerica Thanks!   \n",
       "15             negative      @VirginAmerica SFO-PDX schedule is still MIA.   \n",
       "16             positive  @VirginAmerica So excited for my first cross c...   \n",
       "17             negative  @VirginAmerica  I flew from NYC to SFO last we...   \n",
       "18             positive                    I ‚ù§Ô∏è flying @VirginAmerica. ‚ò∫Ô∏èüëç   \n",
       "19             positive  @VirginAmerica you know what would be amazingl...   \n",
       "20             negative  @VirginAmerica why are your first fares in May...   \n",
       "21             positive  @VirginAmerica I love this graphic. http://t.c...   \n",
       "22             positive  @VirginAmerica I love the hipster innovation. ...   \n",
       "23              neutral  @VirginAmerica will you be making BOS&gt;LAS n...   \n",
       "24             negative  @VirginAmerica you guys messed up my seating.....   \n",
       "25             negative  @VirginAmerica status match program.  I applie...   \n",
       "26             negative  @VirginAmerica What happened 2 ur vegan food o...   \n",
       "27              neutral  @VirginAmerica do you miss me? Don't worry we'...   \n",
       "28             negative  @VirginAmerica amazing to me that we can't get...   \n",
       "29              neutral  @VirginAmerica LAX to EWR - Middle seat on a r...   \n",
       "...                 ...                                                ...   \n",
       "14610          negative  @AmericanAir I understand the weather issue bu...   \n",
       "14611           neutral  @AmericanAir guarantee no retribution? If so, ...   \n",
       "14612          negative  @AmericanAir a friend is having flight Cancell...   \n",
       "14613          negative  @AmericanAir I used the \"call back\" feature wi...   \n",
       "14614          negative  @AmericanAir I need to be at work tomorrow at ...   \n",
       "14615          negative  @AmericanAir  ugh Dump us in dfw w/no luggage ...   \n",
       "14616          negative  @AmericanAir Cancelled Flights my flight, does...   \n",
       "14617          positive            @AmericanAir DMing you now! Big thanks.   \n",
       "14618          negative  @AmericanAir 3078 is overweight so you pull 2 ...   \n",
       "14619          positive  @AmericanAir I love your company and your staf...   \n",
       "14620          negative  @AmericanAir I wait 2+ hrs for CS to call me b...   \n",
       "14621          negative  @AmericanAir I've been on hold for 55 mins abo...   \n",
       "14622          negative  I just need a place to sleep when I land witho...   \n",
       "14623          positive  @AmericanAir Love the new planes for the JFK-L...   \n",
       "14624          negative  @AmericanAir Call me Chairman, or call me Emer...   \n",
       "14625          positive  @AmericanAir Flight 236 was great. Fantastic c...   \n",
       "14626          negative  @AmericanAir Flight 953 NYC-Buenos Aires has b...   \n",
       "14627          negative  @AmericanAir Flight Cancelled Flightled, can't...   \n",
       "14628          positive  Thank you. ‚Äú@AmericanAir: @jlhalldc Customer R...   \n",
       "14629          negative  @AmericanAir How do I change my flight if the ...   \n",
       "14630          positive                        @AmericanAir Thanks! He is.   \n",
       "14631          negative  @AmericanAir thx for nothing on getting us out...   \n",
       "14632           neutral  ‚Äú@AmericanAir: @TilleyMonsta George, that does...   \n",
       "14633          negative  @AmericanAir my flight was Cancelled Flightled...   \n",
       "14634          negative         @AmericanAir right on cue with the delaysüëå   \n",
       "14635          positive  @AmericanAir thank you we got on a different f...   \n",
       "14636          negative  @AmericanAir leaving over 20 minutes Late Flig...   \n",
       "14637           neutral  @AmericanAir Please bring American Airlines to...   \n",
       "14638          negative  @AmericanAir you have my money, you change my ...   \n",
       "14639           neutral  @AmericanAir we have 8 ppl so we need 2 know h...   \n",
       "\n",
       "       sentiment_value  \n",
       "0                  1.0  \n",
       "1                  0.0  \n",
       "2                  1.0  \n",
       "3                  2.0  \n",
       "4                  2.0  \n",
       "5                  2.0  \n",
       "6                  0.0  \n",
       "7                  1.0  \n",
       "8                  0.0  \n",
       "9                  0.0  \n",
       "10                 1.0  \n",
       "11                 0.0  \n",
       "12                 0.0  \n",
       "13                 0.0  \n",
       "14                 0.0  \n",
       "15                 2.0  \n",
       "16                 0.0  \n",
       "17                 2.0  \n",
       "18                 0.0  \n",
       "19                 0.0  \n",
       "20                 2.0  \n",
       "21                 0.0  \n",
       "22                 0.0  \n",
       "23                 1.0  \n",
       "24                 2.0  \n",
       "25                 2.0  \n",
       "26                 2.0  \n",
       "27                 1.0  \n",
       "28                 2.0  \n",
       "29                 1.0  \n",
       "...                ...  \n",
       "14610              2.0  \n",
       "14611              1.0  \n",
       "14612              2.0  \n",
       "14613              2.0  \n",
       "14614              2.0  \n",
       "14615              2.0  \n",
       "14616              2.0  \n",
       "14617              0.0  \n",
       "14618              2.0  \n",
       "14619              0.0  \n",
       "14620              2.0  \n",
       "14621              2.0  \n",
       "14622              2.0  \n",
       "14623              0.0  \n",
       "14624              2.0  \n",
       "14625              0.0  \n",
       "14626              2.0  \n",
       "14627              2.0  \n",
       "14628              0.0  \n",
       "14629              2.0  \n",
       "14630              0.0  \n",
       "14631              2.0  \n",
       "14632              1.0  \n",
       "14633              2.0  \n",
       "14634              2.0  \n",
       "14635              0.0  \n",
       "14636              2.0  \n",
       "14637              1.0  \n",
       "14638              2.0  \n",
       "14639              1.0  \n",
       "\n",
       "[14640 rows x 3 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "airline_sentiments.loc[airline_sentiments['airline_sentiment']=='positive', 'sentiment_value'] = 0\n",
    "airline_sentiments.loc[airline_sentiments['airline_sentiment']=='neutral', 'sentiment_value'] = 1\n",
    "airline_sentiments.loc[airline_sentiments['airline_sentiment']=='negative', 'sentiment_value'] = 2\n",
    "airline_sentiments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are concerned with predicting if a tweet related to US Airlines reflects a positive, neutral or negative sentiment.  For this, we will use the Glove6b obtained from http://nlp.stanford.edu/data/glove.6B.zip to get text_embeddings and then adopt transfer learning to use the text_embeddings with the tweets dataset.\n",
    "\n",
    "### Building a dictionary mapping words in the embedding set to their respective embedding vector with the glove6b dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Indexing word vectors\n",
      "Found 400000 word vectors.\n",
      "Example of Glove Embedding Vector for the word \"hello\" is : \n",
      "[ 0.26688    0.39632    0.6169    -0.77451   -0.1039     0.26697\n",
      "  0.2788     0.30992    0.0054685 -0.085256   0.73602   -0.098432\n",
      "  0.5479    -0.030305   0.33479    0.14094   -0.0070003  0.32569\n",
      "  0.22902    0.46557   -0.19531    0.37491   -0.7139    -0.51775\n",
      "  0.77039    1.0881    -0.66011   -0.16234    0.9119     0.21046\n",
      "  0.047494   1.0019     1.1133     0.70094   -0.08696    0.47571\n",
      "  0.1636    -0.44469    0.4469    -0.93817    0.013101   0.085964\n",
      " -0.67456    0.49662   -0.037827  -0.11038   -0.28612    0.074606\n",
      " -0.31527   -0.093774  -0.57069    0.66865    0.45307   -0.34154\n",
      " -0.7166    -0.75273    0.075212   0.57903   -0.1191    -0.11379\n",
      " -0.10026    0.71341   -1.1574    -0.74026    0.40452    0.18023\n",
      "  0.21449    0.37638    0.11239   -0.53639   -0.025092   0.31886\n",
      " -0.25013   -0.63283   -0.011843   1.377      0.86013    0.20476\n",
      " -0.36815   -0.68874    0.53512   -0.46556    0.27389    0.4118\n",
      " -0.854     -0.046288   0.11304   -0.27326    0.15636   -0.20334\n",
      "  0.53586    0.59784    0.60469    0.13735    0.42232   -0.61279\n",
      " -0.38486    0.35842   -0.48464    0.30728  ]\n"
     ]
    }
   ],
   "source": [
    "print('Indexing word vectors')\n",
    "\n",
    "set = open('glove.6B.100d.txt')\n",
    "\n",
    "embeddings_index = {}\n",
    "\n",
    "for line in set:\n",
    "    values=line.split()\n",
    "    word = values[0]\n",
    "    coefs = np.asarray(values[1:], dtype='float32')\n",
    "    embeddings_index[word] = coefs\n",
    "    \n",
    "print('Found %s word vectors.' % len(embeddings_index))\n",
    "print('Example of Glove Embedding Vector for the word \"hello\" is : \\n{}'.format(embeddings_index['hello']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading the text examples and their respective labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = airline_sentiments['sentiment_value'].tolist()\n",
    "texts = airline_sentiments['text'].tolist()\n",
    "\n",
    "MAX_SEQUENCE_LENGTH = 50\n",
    "MAX_NUM_WORDS = 20000\n",
    "EMBEDDING_DIM = 100\n",
    "VALIDATION_SPLIT = 0.2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tokenizing the words into a 2D integer tensor & Padding so each example is the same length"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The tokenizing of each training example is based on a dictionary where each word corresponds to a number.  Each training example is padded such that its sequence length(i.e number of words) is 50."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 15768 unique tokens.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[   0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,   81,   62, 6686,  226],\n",
       "       [   0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,   81,  558,  590,\n",
       "        1159, 2536,    1,    2,  201, 6687],\n",
       "       [   0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,   81,    3,  207,  102,  805,  591,\n",
       "           3,   76,    1,  156,  150,  193],\n",
       "       [   0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          81,   89,  136, 3792,    1, 4706, 4707, 1009,   15,   21, 6688,\n",
       "        3793,   59,   57,   22,  503, 2798],\n",
       "       [   0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,   81,   10,   89,    4,\n",
       "         136,  476,  214,  487,   84,   20]], dtype=int32)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer = Tokenizer(num_words=MAX_NUM_WORDS)\n",
    "tokenizer.fit_on_texts(texts)\n",
    "sequences = tokenizer.texts_to_sequences(texts)\n",
    "\n",
    "word_index = tokenizer.word_index\n",
    "print('Found %s unique tokens.' % len(word_index))\n",
    "\n",
    "data = pad_sequences(sequences, maxlen=MAX_SEQUENCE_LENGTH)\n",
    "#First 5 examples:\n",
    "data[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Converting the examples to One-Hot representation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of data tensor: (14640, 50)\n",
      "Shape of label tensor: (14640, 3)\n"
     ]
    }
   ],
   "source": [
    "labels = to_categorical(np.asarray(labels))\n",
    "print('Shape of data tensor:', data.shape)\n",
    "print('Shape of label tensor:', labels.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Splitting into training and test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Doing random shuffling of dataset:\n",
    "indices = np.arange(data.shape[0])\n",
    "np.random.shuffle(indices)\n",
    "data = data[indices]\n",
    "labels = labels[indices]\n",
    "num_validation_samples = int(VALIDATION_SPLIT * data.shape[0])\n",
    "\n",
    "#Splitting into training and test sets:\n",
    "x_train = data[:-num_validation_samples]\n",
    "y_train = labels[:-num_validation_samples]\n",
    "x_val = data[-num_validation_samples:]\n",
    "y_val = labels[-num_validation_samples:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preparing Embedding Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preparing embedding matrix.\n"
     ]
    }
   ],
   "source": [
    "print('Preparing embedding matrix.')\n",
    "\n",
    "# prepare embedding matrix\n",
    "num_words = min(MAX_NUM_WORDS, len(word_index)) + 1\n",
    "embedding_matrix = np.zeros((num_words, EMBEDDING_DIM))\n",
    "for word, i in word_index.items():\n",
    "    if i > MAX_NUM_WORDS:\n",
    "        continue\n",
    "    embedding_vector = embeddings_index.get(word)\n",
    "    if embedding_vector is not None:\n",
    "        # words not found in embedding index will be all-zeros.\n",
    "        embedding_matrix[i] = embedding_vector\n",
    "\n",
    "# load pre-trained word embeddings into an Embedding layer\n",
    "# note that we set trainable = False so as to keep the embeddings fixed\n",
    "embedding_layer = Embedding(num_words,\n",
    "                            EMBEDDING_DIM,\n",
    "                            embeddings_initializer=Constant(embedding_matrix),\n",
    "                            input_length=MAX_SEQUENCE_LENGTH,\n",
    "                            trainable=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Constructing the Model and Compiling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_3 (InputLayer)         [(None, 50)]              0         \n",
      "_________________________________________________________________\n",
      "embedding (Embedding)        (None, 50, 100)           1576900   \n",
      "_________________________________________________________________\n",
      "lstm_2 (LSTM)                (None, 128)               117248    \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 3)                 387       \n",
      "=================================================================\n",
      "Total params: 1,694,535\n",
      "Trainable params: 117,635\n",
      "Non-trainable params: 1,576,900\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "sequence_input = Input(shape=(MAX_SEQUENCE_LENGTH,), dtype='int32')\n",
    "embedded_sequences = embedding_layer(sequence_input)\n",
    "x = LSTM(128)(embedded_sequences)\n",
    "x = Dropout(0.3)(x)\n",
    "preds = Dense(3, activation='softmax')(x)\n",
    "\n",
    "model = Model(sequence_input, preds)\n",
    "\n",
    "model.summary()\n",
    "\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='rmsprop',\n",
    "              metrics=['acc'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 11712 samples, validate on 2928 samples\n",
      "WARNING:tensorflow:From /anaconda3/lib/python3.7/site-packages/tensorflow/python/ops/math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "Epoch 1/10\n",
      "11712/11712 [==============================] - 16s 1ms/sample - loss: 0.7502 - acc: 0.6942 - val_loss: 0.6820 - val_acc: 0.7176\n",
      "Epoch 2/10\n",
      "11712/11712 [==============================] - 15s 1ms/sample - loss: 0.6366 - acc: 0.7408 - val_loss: 0.6047 - val_acc: 0.7490\n",
      "Epoch 3/10\n",
      "11712/11712 [==============================] - 15s 1ms/sample - loss: 0.5953 - acc: 0.7587 - val_loss: 0.5876 - val_acc: 0.7596\n",
      "Epoch 4/10\n",
      "11712/11712 [==============================] - 16s 1ms/sample - loss: 0.5615 - acc: 0.7739 - val_loss: 0.6126 - val_acc: 0.7507\n",
      "Epoch 5/10\n",
      "11712/11712 [==============================] - 15s 1ms/sample - loss: 0.5441 - acc: 0.7824 - val_loss: 0.6088 - val_acc: 0.7517\n",
      "Epoch 6/10\n",
      "11712/11712 [==============================] - 15s 1ms/sample - loss: 0.5189 - acc: 0.7858 - val_loss: 0.5764 - val_acc: 0.7698\n",
      "Epoch 7/10\n",
      "11712/11712 [==============================] - 15s 1ms/sample - loss: 0.4970 - acc: 0.8007 - val_loss: 0.5719 - val_acc: 0.7729\n",
      "Epoch 8/10\n",
      "11712/11712 [==============================] - 15s 1ms/sample - loss: 0.4823 - acc: 0.8054 - val_loss: 0.5824 - val_acc: 0.7698\n",
      "Epoch 9/10\n",
      "11712/11712 [==============================] - 15s 1ms/sample - loss: 0.4621 - acc: 0.8134 - val_loss: 0.5752 - val_acc: 0.7667\n",
      "Epoch 10/10\n",
      "11712/11712 [==============================] - 15s 1ms/sample - loss: 0.4462 - acc: 0.8243 - val_loss: 0.5623 - val_acc: 0.7801\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0xb30d66518>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train, y_train,\n",
    "          batch_size=128,\n",
    "          epochs=10,\n",
    "          validation_data=(x_val, y_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluating the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2928/2928 [==============================] - 2s 534us/sample - loss: 0.5623 - acc: 0.7801\n",
      "\n",
      "Test accuracy =  0.7800546\n"
     ]
    }
   ],
   "source": [
    "loss, acc = model.evaluate(x_val, y_val)\n",
    "print()\n",
    "print(\"Test accuracy = \", acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An accuracy of 78 percent was achieved with this model! In future, the model could also take in other factors such as which airlines is the tweet referring to (e.g. #UnitedAirlines), how confidence level for the labeling for each training example etc to get an even more accurate model."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
